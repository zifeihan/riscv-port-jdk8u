/*
 * Copyright (c) 1997, 2012, Oracle and/or its affiliates. All rights reserved.
 * Copyright (c) 2014, Red Hat Inc. All rights reserved.
 * Copyright (c) 2020, Huawei Technologies Co., Ltd. All rights reserved.
 * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
 *
 * This code is free software; you can redistribute it and/or modify it
 * under the terms of the GNU General Public License version 2 only, as
 * published by the Free Software Foundation.
 *
 * This code is distributed in the hope that it will be useful, but WITHOUT
 * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 * version 2 for more details (a copy is included in the LICENSE file that
 * accompanied this code).
 *
 * You should have received a copy of the GNU General Public License version
 * 2 along with this work; if not, write to the Free Software Foundation,
 * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 *
 * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 * or visit www.oracle.com if you need additional information or have any
 * questions.
 */

#include <stdio.h>
#include <sys/types.h>

#include "precompiled.hpp"
#include "asm/assembler.hpp"
#include "asm/assembler.inline.hpp"
#include "compiler/disassembler.hpp"
#include "interpreter/interpreter.hpp"
#include "memory/resourceArea.hpp"
#include "runtime/interfaceSupport.hpp"
#include "runtime/sharedRuntime.hpp"

extern "C" void test_assembler_entry(CodeBuffer *cb);

#define __ _masm.

#ifdef ASSERT
static void asm_check(const unsigned int *insns, const unsigned int *insns1, size_t len) {
  assert_cond(insns != NULL && insns1 != NULL);
  bool ok = true;
  for (unsigned int i = 0; i < len; i++) {
    if (insns[i] != insns1[i]) {
      ok = false;
      printf("Ours:\n");
      Disassembler::decode((address)&insns1[i], (address)&insns1[i+1]);
      printf("Theirs:\n");
      Disassembler::decode((address)&insns[i], (address)&insns[i+1]);
      printf("\n");
    }
  }
  assert(ok, "Assembler smoke test failed");
}
#endif

void test_assembler_entry(CodeBuffer *cb) {
  MacroAssembler _masm(cb);
  address entry = __ pc();

#ifdef ASSERT
    // BEGIN  Generated code -- do not edit
    // Generated by riscv64-asmtest.py
    Label back, forth;
    __ bind(back);

// ArithOp
    __ add(x30, x14, x25);                             // add x30, x14, x25
    __ sub(x24, x20, x20);                             // sub x24, x20, x20
    __ addw(x9, x22, x28);                             // addw  x9, x22, x28
    __ subw(x7, x24, x30);                             // subw  x7, x24, x30
    __ orr(x28, x8, x13);                              // or  x28, x8, x13
    __ xorr(x7, x7, x4);                               // xor x7, x7, x4
    __ mul(x31, x23, x19);                             // mul x31, x23, x19
    __ mulh(x9, x3, x3);                               // mulh  x9, x3, x3
    __ mulhsu(x29, x25, x1);                           // mulhsu  x29, x25, x1
    __ mulhu(x23, x5, x25);                            // mulhu x23, x5, x25
    __ div(x12, x17, x4);                              // div x12, x17, x4
    __ divu(x19, x31, x28);                            // divu  x19, x31, x28
    __ rem(x19, x31, x22);                             // rem x19, x31, x22
    __ remu(x6, x29, x19);                             // remu  x6, x29, x19
    __ mulw(x11, x29, x2);                             // mulw  x11, x29, x2
    __ divw(x13, x19, x19);                            // divw  x13, x19, x19
    __ divuw(x22, x10, x6);                            // divuw x22, x10, x6
    __ remw(x18, x15, x6);                             // remw  x18, x15, x6
    __ remuw(x11, x16, x8);                            // remuw x11, x16, x8
    __ andr(x22, x20, x18);                            // and x22, x20, x18

// AddSubImmOp
    __ addi(x9, x2, 311u);                             // addi  x9, x2, 0x137
    __ addiw(x2, x25, 1907u);                          // addiw x2, x25, 0x773

// LogicalImmOp
    __ ori(x15, x1, 1657u);                            // ori x15, x1, 0x679
    __ xori(x13, x22, 425u);                           // xori  x13, x22, 0x1a9
    __ andi(x2, x26, 480u);                            // andi  x2, x26, 0x1e0

// AbsOp
    __ j(__ pc());                                     // j .
    __ j(back);                                        // j back
    __ j(forth);                                       // j forth
    __ jal(__ pc());                                   // jal .
    __ jal(back);                                      // jal back
    __ jal(forth);                                     // jal forth

// TwoRegAbsOp
    __ jalr(x8, x24, 1727u);                           // jalr  x8, x24, 1727

// LoadImmedOp
    __ lui(x7, 0x557000);                              // lui x7, 0x557
    __ auipc(x4, 0x15e9a000);                          // auipc x4, 0x15e9a

// RegAndAbsOp
    __ bnez(x8, __ pc());                              // bnez  x8, .
    __ bnez(x8, back);                                 // bnez  x8, back
    __ bnez(x8, forth);                                // bnez  x8, forth
    __ beqz(x1, __ pc());                              // beqz  x1, .
    __ beqz(x1, back);                                 // beqz  x1, back
    __ beqz(x1, forth);                                // beqz  x1, forth

// TwoRegAndAbsOp
    __ bne(x20, x2, __ pc());                          // bne x20, x2, .
    __ bne(x20, x2, back);                             // bne x20, x2, back
    __ bne(x20, x2, forth);                            // bne x20, x2, forth
    __ beq(x13, x29, __ pc());                         // beq x13, x29, .
    __ beq(x13, x29, back);                            // beq x13, x29, back
    __ beq(x13, x29, forth);                           // beq x13, x29, forth
    __ bge(x9, x7, __ pc());                           // bge x9, x7, .
    __ bge(x9, x7, back);                              // bge x9, x7, back
    __ bge(x9, x7, forth);                             // bge x9, x7, forth
    __ bgeu(x7, x4, __ pc());                          // bgeu  x7, x4, .
    __ bgeu(x7, x4, back);                             // bgeu  x7, x4, back
    __ bgeu(x7, x4, forth);                            // bgeu  x7, x4, forth
    __ blt(x9, x29, __ pc());                          // blt x9, x29, .
    __ blt(x9, x29, back);                             // blt x9, x29, back
    __ blt(x9, x29, forth);                            // blt x9, x29, forth
    __ bltu(x17, x25, __ pc());                        // bltu  x17, x25, .
    __ bltu(x17, x25, back);                           // bltu  x17, x25, back
    __ bltu(x17, x25, forth);                          // bltu  x17, x25, forth

// TwoRegImmedOp
    __ slti(x20, x14, 1583u);                          // slti  x20, x14, 1583
    __ sltiu(x16, x11, 615u);                          // sltiu x16, x11, 615

// ShiftRegOp
    __ sll(x1, x27, x19);                              // sll x1, x27, x19
    __ srl(x23, x18, x24);                             // srl x23, x18, x24
    __ sra(x11, x9, x26);                              // sra x11, x9, x26
    __ sraw(x6, x25, x18);                             // sraw  x6, x25, x18
    __ sllw(x1, x13, x7);                              // sllw  x1, x13, x7
    __ srlw(x19, x21, x22);                            // srlw  x19, x21, x22

// ShiftImmOp
    __ slli(x13, x25, 1u);                             // slli  x13, x25, 0x1
    __ srli(x1, x9, 0u);                               // srli  x1, x9, 0x0
    __ srai(x22, x30, 1u);                             // srai  x22, x30, 0x1
    __ slliw(x6, x23, 16u);                            // slliw x6, x23, 0x10
    __ srliw(x25, x6, 9u);                             // srliw x25, x6, 0x9
    __ sraiw(x18, x16, 12u);                           // sraiw x18, x16, 0xc

// Op
    __ nop();                                          // nop
    __ ecall();                                        // ecall
    __ ebreak();                                       // ebreak
    __ fence_i();                                      // fence.i

// SystemOp
    __ fence(4u, 1u);                                  // fence o, w

// AtomOp
    __ sc_w(x19, x16, x2, Assembler::aq);              // sc.w.aq x19, x16, (x2)
    __ amoswap_w(x30, x29, x16, Assembler::aq);        // amoswap.w.aq  x30, x16, (x29)
    __ amoadd_w(x30, x19, x24, Assembler::aq);         // amoadd.w.aq x30, x24, (x19)
    __ amoxor_w(x2, x7, x21, Assembler::aq);           // amoxor.w.aq x2, x21, (x7)
    __ amoand_w(x28, x3, x25, Assembler::aq);          // amoand.w.aq x28, x25, (x3)
    __ amoor_w(x1, x11, x4, Assembler::aq);            // amoor.w.aq  x1, x4, (x11)
    __ amomin_w(x5, x4, x11, Assembler::aq);           // amomin.w.aq x5, x11, (x4)
    __ amomax_w(x8, x12, x31, Assembler::aq);          // amomax.w.aq x8, x31, (x12)
    __ amominu_w(x20, x16, x17, Assembler::aq);        // amominu.w.aq  x20, x17, (x16)
    __ amomaxu_w(x31, x12, x23, Assembler::aq);        // amomaxu.w.aq  x31, x23, (x12)
    __ lr_w(x31, x12, Assembler::aq);                  // lr.w.aq x31, (x12)

// AtomOp
    __ sc_w(x19, x2, x31, Assembler::rl);              // sc.w.rl x19, x2, (x31)
    __ amoswap_w(x19, x18, x30, Assembler::rl);        // amoswap.w.rl  x19, x30, (x18)
    __ amoadd_w(x1, x5, x16, Assembler::rl);           // amoadd.w.rl x1, x16, (x5)
    __ amoxor_w(x17, x29, x11, Assembler::rl);         // amoxor.w.rl x17, x11, (x29)
    __ amoand_w(x28, x18, x7, Assembler::rl);          // amoand.w.rl x28, x7, (x18)
    __ amoor_w(x31, x16, x5, Assembler::rl);           // amoor.w.rl  x31, x5, (x16)
    __ amomin_w(x5, x8, x10, Assembler::rl);           // amomin.w.rl x5, x10, (x8)
    __ amomax_w(x3, x22, x9, Assembler::rl);           // amomax.w.rl x3, x9, (x22)
    __ amominu_w(x18, x11, x3, Assembler::rl);         // amominu.w.rl  x18, x3, (x11)
    __ amomaxu_w(x7, x23, x2, Assembler::rl);          // amomaxu.w.rl  x7, x2, (x23)
    __ lr_w(x16, x27, Assembler::rl);                  // lr.w.rl x16, (x27)

// AtomOp
    __ sc_d(x28, x16, x17, Assembler::aq);             // sc.d.aq x28, x16, (x17)
    __ amoswap_d(x31, x13, x3, Assembler::aq);         // amoswap.d.aq  x31, x3, (x13)
    __ amoadd_d(x11, x8, x29, Assembler::aq);          // amoadd.d.aq x11, x29, (x8)
    __ amoxor_d(x13, x31, x5, Assembler::aq);          // amoxor.d.aq x13, x5, (x31)
    __ amoand_d(x31, x9, x7, Assembler::aq);           // amoand.d.aq x31, x7, (x9)
    __ amoor_d(x7, x14, x1, Assembler::aq);            // amoor.d.aq  x7, x1, (x14)
    __ amomin_d(x18, x25, x24, Assembler::aq);         // amomin.d.aq x18, x24, (x25)
    __ amomax_d(x18, x6, x6, Assembler::aq);           // amomax.d.aq x18, x6, (x6)
    __ amominu_d(x25, x21, x21, Assembler::aq);        // amominu.d.aq  x25, x21, (x21)
    __ amomaxu_d(x16, x29, x27, Assembler::aq);        // amomaxu.d.aq  x16, x27, (x29)
    __ lr_d(x1, x25, Assembler::aq);                   // lr.d.aq x1, (x25)

// AtomOp
    __ sc_d(x26, x9, x18, Assembler::rl);              // sc.d.rl x26, x9, (x18)
    __ amoswap_d(x9, x16, x2, Assembler::rl);          // amoswap.d.rl  x9, x2, (x16)
    __ amoadd_d(x14, x23, x27, Assembler::rl);         // amoadd.d.rl x14, x27, (x23)
    __ amoxor_d(x28, x2, x20, Assembler::rl);          // amoxor.d.rl x28, x20, (x2)
    __ amoand_d(x16, x5, x7, Assembler::rl);           // amoand.d.rl x16, x7, (x5)
    __ amoor_d(x14, x4, x6, Assembler::rl);            // amoor.d.rl  x14, x6, (x4)
    __ amomin_d(x31, x8, x3, Assembler::rl);           // amomin.d.rl x31, x3, (x8)
    __ amomax_d(x16, x9, x3, Assembler::rl);           // amomax.d.rl x16, x3, (x9)
    __ amominu_d(x23, x4, x30, Assembler::rl);         // amominu.d.rl  x23, x30, (x4)
    __ amomaxu_d(x3, x15, x5, Assembler::rl);          // amomaxu.d.rl  x3, x5, (x15)
    __ lr_d(x27, x9, Assembler::rl);                   // lr.d.rl x27, (x9)

// OneRegOp
    __ frflags(x15);                                   // frflags x15
    __ frrm(x25);                                      // frrm  x25
    __ frcsr(x16);                                     // frcsr x16
    __ rdtime(x26);                                    // rdtime  x26
    __ rdcycle(x27);                                   // rdcycle x27
    __ rdinstret(x4);                                  // rdinstret x4

// TwoRegOp
    __ mv(x20, x16);                                   // mv  x20, x16
    __ notr(x18, x6);                                  // not x18, x6
    __ neg(x20, x15);                                  // neg x20, x15
    __ negw(x8, x27);                                  // negw  x8, x27
    __ sext_w(x1, x14);                                // sext.w  x1, x14
    __ seqz(x11, x25);                                 // seqz  x11, x25
    __ snez(x16, x26);                                 // snez  x16, x26
    __ sltz(x13, x29);                                 // sltz  x13, x29
    __ sgtz(x11, x25);                                 // sgtz  x11, x25
    __ fscsr(x11, x20);                                // fscsr x11, x20
    __ fsrm(x23, x30);                                 // fsrm  x23, x30
    __ fsflags(x6, x22);                               // fsflags x6, x22

// ThreeRegOp
    __ slt(x7, x30, x7);                               // slt x7, x30, x7
    __ sltu(x12, x24, x31);                            // sltu  x12, x24, x31

// CsrxixOp
    __ csrrw(x12, 1723, x3);                           // csrrw x12, 0x6bb, x3
    __ csrrs(x24, 71, x4);                             // csrrs x24, 0x47, x4
    __ csrrc(x22, 506, x8);                            // csrrc x22, 0x1fa, x8

// CsrxiiOp
    __ csrrwi(x16, 1398, 9);                           // csrrwi  x16, 0x576, 9
    __ csrrsi(x25, 1435, 14);                          // csrrsi  x25, 0x59b, 14
    __ csrrci(x22, 1971, 9);                           // csrrci  x22, 0x7b3, 9

// CsrxiOp
    __ csrr(x13, 0x3b9);                               // csrr  x13, 0x3b9

// CsrixOp
    __ csrw(0x545, x30);                               // csrw  0x545, x30
    __ csrs(0x5e6, x26);                               // csrs  0x5e6, x26
    __ csrc(0x726, x8);                                // csrc  0x726, x8

// CsriiOp
    __ csrwi(0x11d, 8);                                // csrwi 0x11d, 8
    __ csrsi(0x66d, 7);                                // csrsi 0x66d, 7
    __ csrci(0x5c6, 8);                                // csrci 0x5c6, 8

// LoadStoreOp
    __ ld(x28, Address(x18, -1864));                   // ld   x28, -1864(x18)
    __ lw(x31, Address(x7, -53));                      // lw   x31, -53(x7)
    __ lwu(x1, Address(x11, -362));                    // lwu  x1, -362(x11)
    __ lh(x23, Address(x20, -1070));                   // lh   x23, -1070(x20)
    __ lhu(x24, Address(x22, -1377));                  // lhu  x24, -1377(x22)
    __ lb(x31, Address(x13, -206));                    // lb   x31, -206(x13)
    __ lbu(x20, Address(x31, -1597));                  // lbu  x20, -1597(x31)
    __ sd(x4, Address(x3, 861));                       // sd   x4, 861(x3)
    __ sw(x2, Address(x22, 363));                      // sw   x2, 363(x22)
    __ sh(x13, Address(x10, 257));                     // sh   x13, 257(x10)
    __ sb(x30, Address(x10, 487));                     // sb   x30, 487(x10)
    __ fld(f15, Address(x31, -2035));                  // fld  f15, -2035(x31)
    __ flw(f20, Address(x6, -1957));                   // flw  f20, -1957(x6)
    __ fsd(f8, Address(x26, 111));                     // fsd  f8, 111(x26)
    __ fsw(f14, Address(x23, -112));                   // fsw  f14, -112(x23)

// Float2ArithOp
    __ fsqrt_s(f26, f9, Assembler::rdn);               // fsqrt.s f26, f9, rdn
    __ fsqrt_d(f13, f4, Assembler::rdn);               // fsqrt.d f13, f4, rdn

// Float3ArithOp
    __ fadd_s(f10, f10, f11, Assembler::rup);          // fadd.s  f10, f10, f11, rup
    __ fsub_s(f6, f30, f4, Assembler::rup);            // fsub.s  f6, f30, f4, rup
    __ fadd_d(f21, f21, f23, Assembler::rup);          // fadd.d  f21, f21, f23, rup
    __ fsub_d(f28, f19, f19, Assembler::rup);          // fsub.d  f28, f19, f19, rup
    __ fmul_s(f7, f20, f3, Assembler::rup);            // fmul.s  f7, f20, f3, rup
    __ fdiv_s(f20, f27, f17, Assembler::rup);          // fdiv.s  f20, f27, f17, rup
    __ fmul_d(f10, f11, f19, Assembler::rup);          // fmul.d  f10, f11, f19, rup
    __ fdiv_d(f12, f30, f24, Assembler::rup);          // fdiv.d  f12, f30, f24, rup

// Float4ArithOp
    __ fmadd_s(f24, f16, f21, f19, Assembler::rup);    // fmadd.s f24, f16, f21, f19, rup
    __ fmsub_s(f12, f5, f27, f5, Assembler::rtz);      // fmsub.s f12, f5, f27, f5, rtz
    __ fmadd_d(f13, f26, f9, f2, Assembler::rup);      // fmadd.d f13, f26, f9, f2, rup
    __ fmsub_d(f4, f28, f2, f8, Assembler::rtz);       // fmsub.d f4, f28, f2, f8, rtz
    __ fnmsub_s(f26, f1, f8, f1, Assembler::rmm);      // fnmsub.s  f26, f1, f8, f1, rmm
    __ fnmadd_s(f20, f7, f10, f16, Assembler::rtz);    // fnmadd.s  f20, f7, f10, f16, rtz
    __ fnmsub_d(f20, f6, f11, f17, Assembler::rmm);    // fnmsub.d  f20, f6, f11, f17, rmm
    __ fnmadd_d(f8, f16, f30, f21, Assembler::rtz);    // fnmadd.d  f8, f16, f30, f21, rtz

// TwoRegFloatOp
    __ fclass_s(x10, f21);                             // fclass.s  x10, f21
    __ fmv_s(f22, f15);                                // fmv.s f22, f15
    __ fclass_d(x22, f31);                             // fclass.d  x22, f31
    __ fmv_d(f19, f4);                                 // fmv.d f19, f4
    __ fabs_s(f14, f7);                                // fabs.s  f14, f7
    __ fneg_s(f19, f16);                               // fneg.s  f19, f16
    __ fabs_d(f30, f20);                               // fabs.d  f30, f20
    __ fneg_d(f6, f10);                                // fneg.d  f6, f10
    __ fmv_x_w(x3, f2);                                // fmv.x.w x3, f2
    __ fmv_x_d(x7, f22);                               // fmv.x.d x7, f22

// ThreeRegFloatOp
    __ fsgnj_s(f22, f2, f27);                          // fsgnj.s f22, f2, f27
    __ fsgnjn_s(f15, f13, f31);                        // fsgnjn.s  f15, f13, f31
    __ fsgnj_d(f26, f18, f26);                         // fsgnj.d f26, f18, f26
    __ fsgnjn_d(f20, f23, f1);                         // fsgnjn.d  f20, f23, f1
    __ fsgnjx_s(f16, f5, f7);                          // fsgnjx.s  f16, f5, f7
    __ fmin_s(f1, f31, f30);                           // fmin.s  f1, f31, f30
    __ fsgnjx_d(f12, f11, f10);                        // fsgnjx.d  f12, f11, f10
    __ fmin_d(f11, f3, f16);                           // fmin.d  f11, f3, f16
    __ fmax_s(f31, f10, f17);                          // fmax.s  f31, f10, f17
    __ feq_s(x3, f17, f27);                            // feq.s x3, f17, f27
    __ fmax_d(f29, f12, f13);                          // fmax.d  f29, f12, f13
    __ feq_d(x2, f28, f24);                            // feq.d x2, f28, f24
    __ flt_s(x10, f21, f18);                           // flt.s x10, f21, f18
    __ fle_s(x7, f21, f14);                            // fle.s x7, f21, f14
    __ flt_d(x11, f16, f19);                           // flt.d x11, f16, f19
    __ fle_d(x13, f24, f5);                            // fle.d x13, f24, f5

// FloatConvertOp
    __ fcvt_w_s(x9, f30, Assembler::rup);              // fcvt.w.s  x9, f30, rup
    __ fcvt_wu_s(x22, f12, Assembler::rne);            // fcvt.wu.s x22, f12, rne
    __ fcvt_s_w(f31, x20, Assembler::rdn);             // fcvt.s.w  f31, x20, rdn
    __ fcvt_s_wu(f25, x24, Assembler::rtz);            // fcvt.s.wu f25, x24, rtz
    __ fcvt_l_s(x30, f29, Assembler::rne);             // fcvt.l.s  x30, f29, rne
    __ fcvt_lu_s(x24, f6, Assembler::rmm);             // fcvt.lu.s x24, f6, rmm
    __ fcvt_s_l(f28, x5, Assembler::rup);              // fcvt.s.l  f28, x5, rup
    __ fcvt_s_lu(f25, x8, Assembler::rtz);             // fcvt.s.lu f25, x8, rtz
    __ fcvt_s_d(f27, f30, Assembler::rdn);             // fcvt.s.d  f27, f30, rdn
    __ fcvt_d_s(f12, f15, Assembler::rne);             // fcvt.d.s  f12, f15
    __ fcvt_w_d(x1, f30, Assembler::rdn);              // fcvt.w.d  x1, f30, rdn
    __ fcvt_wu_d(x28, f18, Assembler::rdn);            // fcvt.wu.d x28, f18, rdn
    __ fcvt_d_w(f31, x27, Assembler::rne);             // fcvt.d.w  f31, x27
    __ fcvt_d_wu(f23, x4, Assembler::rne);             // fcvt.d.wu f23, x4
    __ fcvt_l_d(x18, f25, Assembler::rdn);             // fcvt.l.d  x18, f25, rdn
    __ fcvt_lu_d(x31, f9, Assembler::rdn);             // fcvt.lu.d x31, f9, rdn
    __ fcvt_d_l(f19, x7, Assembler::rdn);              // fcvt.d.l  f19, x7, rdn
    __ fcvt_d_lu(f7, x10, Assembler::rdn);             // fcvt.d.lu f7, x10, rdn

    __ bind(forth);

/*
riscv64ops.o:     file format elf64-littleriscv


Disassembly of section .text:

0000000000000000 <back>:
   0: 01970f33            add t5,a4,s9
   4: 414a0c33            sub s8,s4,s4
   8: 01cb04bb            addw  s1,s6,t3
   c: 41ec03bb            subw  t2,s8,t5
  10: 00d46e33            or  t3,s0,a3
  14: 0043c3b3            xor t2,t2,tp
  18: 033b8fb3            mul t6,s7,s3
  1c: 023194b3            mulh  s1,gp,gp
  20: 021caeb3            mulhsu  t4,s9,ra
  24: 0392bbb3            mulhu s7,t0,s9
  28: 0248c633            div a2,a7,tp
  2c: 03cfd9b3            divu  s3,t6,t3
  30: 036fe9b3            rem s3,t6,s6
  34: 033ef333            remu  t1,t4,s3
  38: 022e85bb            mulw  a1,t4,sp
  3c: 0339c6bb            divw  a3,s3,s3
  40: 02655b3b            divuw s6,a0,t1
  44: 0267e93b            remw  s2,a5,t1
  48: 028875bb            remuw a1,a6,s0
  4c: 012a7b33            and s6,s4,s2
  50: 13710493            addi  s1,sp,311
  54: 773c811b            addiw sp,s9,1907
  58: 6790e793            ori a5,ra,1657
  5c: 1a9b4693            xori  a3,s6,425
  60: 1e0d7113            andi  sp,s10,480
  64: 0000006f            j 64 <back+0x64>
  68: f99ff06f            j 0 <back>
  6c: 3300006f            j 39c <forth>
  70: 000000ef            jal ra,70 <back+0x70>
  74: f8dff0ef            jal ra,0 <back>
  78: 324000ef            jal ra,39c <forth>
  7c: 6bfc0467            jalr  s0,1727(s8)
  80: 005573b7            lui t2,0x557
  84: 15e9a217            auipc tp,0x15e9a
  88: 00041063            bnez  s0,88 <back+0x88>
  8c: f6041ae3            bnez  s0,0 <back>
  90: 30041663            bnez  s0,39c <forth>
  94: 00008063            beqz  ra,94 <back+0x94>
  98: f60084e3            beqz  ra,0 <back>
  9c: 30008063            beqz  ra,39c <forth>
  a0: 002a1063            bne s4,sp,a0 <back+0xa0>
  a4: f42a1ee3            bne s4,sp,0 <back>
  a8: 2e2a1a63            bne s4,sp,39c <forth>
  ac: 01d68063            beq a3,t4,ac <back+0xac>
  b0: f5d688e3            beq a3,t4,0 <back>
  b4: 2fd68463            beq a3,t4,39c <forth>
  b8: 0074d063            bge s1,t2,b8 <back+0xb8>
  bc: f474d2e3            bge s1,t2,0 <back>
  c0: 2c74de63            bge s1,t2,39c <forth>
  c4: 0043f063            bgeu  t2,tp,c4 <back+0xc4>
  c8: f243fce3            bgeu  t2,tp,0 <back>
  cc: 2c43f863            bgeu  t2,tp,39c <forth>
  d0: 01d4c063            blt s1,t4,d0 <back+0xd0>
  d4: f3d4c6e3            blt s1,t4,0 <back>
  d8: 2dd4c263            blt s1,t4,39c <forth>
  dc: 0198e063            bltu  a7,s9,dc <back+0xdc>
  e0: f398e0e3            bltu  a7,s9,0 <back>
  e4: 2b98ec63            bltu  a7,s9,39c <forth>
  e8: 62f72a13            slti  s4,a4,1583
  ec: 2675b813            sltiu a6,a1,615
  f0: 013d90b3            sll ra,s11,s3
  f4: 01895bb3            srl s7,s2,s8
  f8: 41a4d5b3            sra a1,s1,s10
  fc: 412cd33b            sraw  t1,s9,s2
 100: 007690bb            sllw  ra,a3,t2
 104: 016ad9bb            srlw  s3,s5,s6
 108: 001c9693            slli  a3,s9,0x1
 10c: 0004d093            srli  ra,s1,0x0
 110: 401f5b13            srai  s6,t5,0x1
 114: 010b931b            slliw t1,s7,0x10
 118: 00935c9b            srliw s9,t1,0x9
 11c: 40c8591b            sraiw s2,a6,0xc
 120: 00000013            nop
 124: 00000073            ecall
 128: 00100073            ebreak
 12c: 0000100f            fence.i
 130: 0410000f            fence o,w
 134: 1d0129af            sc.w.aq s3,a6,(sp)
 138: 0d0eaf2f            amoswap.w.aq  t5,a6,(t4)
 13c: 0589af2f            amoadd.w.aq t5,s8,(s3)
 140: 2553a12f            amoxor.w.aq sp,s5,(t2)
 144: 6591ae2f            amoand.w.aq t3,s9,(gp)
 148: 4445a0af            amoor.w.aq  ra,tp,(a1)
 14c: 84b222af            amomin.w.aq t0,a1,(tp)
 150: a5f6242f            amomax.w.aq s0,t6,(a2)
 154: c5182a2f            amominu.w.aq  s4,a7,(a6)
 158: e5762faf            amomaxu.w.aq  t6,s7,(a2)
 15c: 14062faf            lr.w.aq t6,(a2)
 160: 1a2fa9af            sc.w.rl s3,sp,(t6)
 164: 0be929af            amoswap.w.rl  s3,t5,(s2)
 168: 0302a0af            amoadd.w.rl ra,a6,(t0)
 16c: 22bea8af            amoxor.w.rl a7,a1,(t4)
 170: 62792e2f            amoand.w.rl t3,t2,(s2)
 174: 42582faf            amoor.w.rl  t6,t0,(a6)
 178: 82a422af            amomin.w.rl t0,a0,(s0)
 17c: a29b21af            amomax.w.rl gp,s1,(s6)
 180: c235a92f            amominu.w.rl  s2,gp,(a1)
 184: e22ba3af            amomaxu.w.rl  t2,sp,(s7)
 188: 120da82f            lr.w.rl a6,(s11)
 18c: 1d08be2f            sc.d.aq t3,a6,(a7)
 190: 0c36bfaf            amoswap.d.aq  t6,gp,(a3)
 194: 05d435af            amoadd.d.aq a1,t4,(s0)
 198: 245fb6af            amoxor.d.aq a3,t0,(t6)
 19c: 6474bfaf            amoand.d.aq t6,t2,(s1)
 1a0: 441733af            amoor.d.aq  t2,ra,(a4)
 1a4: 858cb92f            amomin.d.aq s2,s8,(s9)
 1a8: a463392f            amomax.d.aq s2,t1,(t1)
 1ac: c55abcaf            amominu.d.aq  s9,s5,(s5)
 1b0: e5beb82f            amomaxu.d.aq  a6,s11,(t4)
 1b4: 140cb0af            lr.d.aq ra,(s9)
 1b8: 1a993d2f            sc.d.rl s10,s1,(s2)
 1bc: 0a2834af            amoswap.d.rl  s1,sp,(a6)
 1c0: 03bbb72f            amoadd.d.rl a4,s11,(s7)
 1c4: 23413e2f            amoxor.d.rl t3,s4,(sp)
 1c8: 6272b82f            amoand.d.rl a6,t2,(t0)
 1cc: 4262372f            amoor.d.rl  a4,t1,(tp)
 1d0: 82343faf            amomin.d.rl t6,gp,(s0)
 1d4: a234b82f            amomax.d.rl a6,gp,(s1)
 1d8: c3e23baf            amominu.d.rl  s7,t5,(tp)
 1dc: e257b1af            amomaxu.d.rl  gp,t0,(a5)
 1e0: 1204bdaf            lr.d.rl s11,(s1)
 1e4: 001027f3            frflags a5
 1e8: 00202cf3            frrm  s9
 1ec: 00302873            frcsr a6
 1f0: c0102d73            rdtime  s10
 1f4: c0002df3            rdcycle s11
 1f8: c0202273            rdinstret tp
 1fc: 00080a13            mv  s4,a6
 200: fff34913            not s2,t1
 204: 40f00a33            neg s4,a5
 208: 41b0043b            negw  s0,s11
 20c: 0007009b            sext.w  ra,a4
 210: 001cb593            seqz  a1,s9
 214: 01a03833            snez  a6,s10
 218: 000ea6b3            sltz  a3,t4
 21c: 019025b3            sgtz  a1,s9
 220: 003a15f3            fscsr a1,s4
 224: 002f1bf3            fsrm  s7,t5
 228: 001b1373            fsflags t1,s6
 22c: 007f23b3            slt t2,t5,t2
 230: 01fc3633            sltu  a2,s8,t6
 234: 6bb19673            csrrw a2,0x6bb,gp
 238: 04722c73            csrrs s8,0x47,tp
 23c: 1fa43b73            csrrc s6,0x1fa,s0
 240: 5764d873            csrrwi  a6,0x576,9
 244: 59b76cf3            csrrsi  s9,0x59b,14
 248: 7b34fb73            csrrci  s6,0x7b3,9
 24c: 3b9026f3            csrr  a3,pmpaddr9
 250: 545f1073            csrw  0x545,t5
 254: 5e6d2073            csrs  0x5e6,s10
 258: 72643073            csrc  0x726,s0
 25c: 11d45073            csrwi 0x11d,8
 260: 66d3e073            csrsi 0x66d,7
 264: 5c647073            csrci 0x5c6,8
 268: 8b893e03            ld  t3,-1864(s2)
 26c: fcb3af83            lw  t6,-53(t2) # 556fcb <forth+0x556c2f>
 270: e965e083            lwu ra,-362(a1)
 274: bd2a1b83            lh  s7,-1070(s4)
 278: a9fb5c03            lhu s8,-1377(s6)
 27c: f3268f83            lb  t6,-206(a3)
 280: 9c3fca03            lbu s4,-1597(t6)
 284: 3441bea3            sd  tp,861(gp)
 288: 162b25a3            sw  sp,363(s6)
 28c: 10d510a3            sh  a3,257(a0)
 290: 1fe503a3            sb  t5,487(a0)
 294: 80dfb787            fld fa5,-2035(t6)
 298: 85b32a07            flw fs4,-1957(t1)
 29c: 068d37a7            fsd fs0,111(s10)
 2a0: f8eba827            fsw fa4,-112(s7)
 2a4: 5804ad53            fsqrt.s fs10,fs1,rdn
 2a8: 5a0226d3            fsqrt.d fa3,ft4,rdn
 2ac: 00b53553            fadd.s  fa0,fa0,fa1,rup
 2b0: 084f3353            fsub.s  ft6,ft10,ft4,rup
 2b4: 037abad3            fadd.d  fs5,fs5,fs7,rup
 2b8: 0b39be53            fsub.d  ft8,fs3,fs3,rup
 2bc: 103a33d3            fmul.s  ft7,fs4,ft3,rup
 2c0: 191dba53            fdiv.s  fs4,fs11,fa7,rup
 2c4: 1335b553            fmul.d  fa0,fa1,fs3,rup
 2c8: 1b8f3653            fdiv.d  fa2,ft10,fs8,rup
 2cc: 99583c43            fmadd.s fs8,fa6,fs5,fs3,rup
 2d0: 29b29647            fmsub.s fa2,ft5,fs11,ft5,rtz
 2d4: 129d36c3            fmadd.d fa3,fs10,fs1,ft2,rup
 2d8: 422e1247            fmsub.d ft4,ft8,ft2,fs0,rtz
 2dc: 0880cd4b            fnmsub.s  fs10,ft1,fs0,ft1,rmm
 2e0: 80a39a4f            fnmadd.s  fs4,ft7,fa0,fa6,rtz
 2e4: 8ab34a4b            fnmsub.d  fs4,ft6,fa1,fa7,rmm
 2e8: abe8144f            fnmadd.d  fs0,fa6,ft10,fs5,rtz
 2ec: e00a9553            fclass.s  a0,fs5
 2f0: 20f78b53            fmv.s fs6,fa5
 2f4: e20f9b53            fclass.d  s6,ft11
 2f8: 224209d3            fmv.d fs3,ft4
 2fc: 2073a753            fabs.s  fa4,ft7
 300: 210819d3            fneg.s  fs3,fa6
 304: 234a2f53            fabs.d  ft10,fs4
 308: 22a51353            fneg.d  ft6,fa0
 30c: e00101d3            fmv.x.w gp,ft2
 310: e20b03d3            fmv.x.d t2,fs6
 314: 21b10b53            fsgnj.s fs6,ft2,fs11
 318: 21f697d3            fsgnjn.s  fa5,fa3,ft11
 31c: 23a90d53            fsgnj.d fs10,fs2,fs10
 320: 221b9a53            fsgnjn.d  fs4,fs7,ft1
 324: 2072a853            fsgnjx.s  fa6,ft5,ft7
 328: 29ef80d3            fmin.s  ft1,ft11,ft10
 32c: 22a5a653            fsgnjx.d  fa2,fa1,fa0
 330: 2b0185d3            fmin.d  fa1,ft3,fa6
 334: 29151fd3            fmax.s  ft11,fa0,fa7
 338: a1b8a1d3            feq.s gp,fa7,fs11
 33c: 2ad61ed3            fmax.d  ft9,fa2,fa3
 340: a38e2153            feq.d sp,ft8,fs8
 344: a12a9553            flt.s a0,fs5,fs2
 348: a0ea83d3            fle.s t2,fs5,fa4
 34c: a33815d3            flt.d a1,fa6,fs3
 350: a25c06d3            fle.d a3,fs8,ft5
 354: c00f34d3            fcvt.w.s  s1,ft10,rup
 358: c0160b53            fcvt.wu.s s6,fa2,rne
 35c: d00a2fd3            fcvt.s.w  ft11,s4,rdn
 360: d01c1cd3            fcvt.s.wu fs9,s8,rtz
 364: c02e8f53            fcvt.l.s  t5,ft9,rne
 368: c0334c53            fcvt.lu.s s8,ft6,rmm
 36c: d022be53            fcvt.s.l  ft8,t0,rup
 370: d0341cd3            fcvt.s.lu fs9,s0,rtz
 374: 401f2dd3            fcvt.s.d  fs11,ft10,rdn
 378: 42078653            fcvt.d.s  fa2,fa5
 37c: c20f20d3            fcvt.w.d  ra,ft10,rdn
 380: c2192e53            fcvt.wu.d t3,fs2,rdn
 384: d20d8fd3            fcvt.d.w  ft11,s11
 388: d2120bd3            fcvt.d.wu fs7,tp
 38c: c22ca953            fcvt.l.d  s2,fs9,rdn
 390: c234afd3            fcvt.lu.d t6,fs1,rdn
 394: d223a9d3            fcvt.d.l  fs3,t2,rdn
 398: d23523d3            fcvt.d.lu ft7,a0,rdn
 */

  static const unsigned int insns[] =
  {
    0x01970f33,     0x414a0c33,     0x01cb04bb,     0x41ec03bb,
    0x00d46e33,     0x0043c3b3,     0x033b8fb3,     0x023194b3,
    0x021caeb3,     0x0392bbb3,     0x0248c633,     0x03cfd9b3,
    0x036fe9b3,     0x033ef333,     0x022e85bb,     0x0339c6bb,
    0x02655b3b,     0x0267e93b,     0x028875bb,     0x012a7b33,
    0x13710493,     0x773c811b,     0x6790e793,     0x1a9b4693,
    0x1e0d7113,     0x0000006f,     0xf99ff06f,     0x3300006f,
    0x000000ef,     0xf8dff0ef,     0x324000ef,     0x6bfc0467,
    0x005573b7,     0x15e9a217,     0x00041063,     0xf6041ae3,
    0x30041663,     0x00008063,     0xf60084e3,     0x30008063,
    0x002a1063,     0xf42a1ee3,     0x2e2a1a63,     0x01d68063,
    0xf5d688e3,     0x2fd68463,     0x0074d063,     0xf474d2e3,
    0x2c74de63,     0x0043f063,     0xf243fce3,     0x2c43f863,
    0x01d4c063,     0xf3d4c6e3,     0x2dd4c263,     0x0198e063,
    0xf398e0e3,     0x2b98ec63,     0x62f72a13,     0x2675b813,
    0x013d90b3,     0x01895bb3,     0x41a4d5b3,     0x412cd33b,
    0x007690bb,     0x016ad9bb,     0x001c9693,     0x0004d093,
    0x401f5b13,     0x010b931b,     0x00935c9b,     0x40c8591b,
    0x00000013,     0x00000073,     0x00100073,     0x0000100f,
    0x0410000f,     0x1d0129af,     0x0d0eaf2f,     0x0589af2f,
    0x2553a12f,     0x6591ae2f,     0x4445a0af,     0x84b222af,
    0xa5f6242f,     0xc5182a2f,     0xe5762faf,     0x14062faf,
    0x1a2fa9af,     0x0be929af,     0x0302a0af,     0x22bea8af,
    0x62792e2f,     0x42582faf,     0x82a422af,     0xa29b21af,
    0xc235a92f,     0xe22ba3af,     0x120da82f,     0x1d08be2f,
    0x0c36bfaf,     0x05d435af,     0x245fb6af,     0x6474bfaf,
    0x441733af,     0x858cb92f,     0xa463392f,     0xc55abcaf,
    0xe5beb82f,     0x140cb0af,     0x1a993d2f,     0x0a2834af,
    0x03bbb72f,     0x23413e2f,     0x6272b82f,     0x4262372f,
    0x82343faf,     0xa234b82f,     0xc3e23baf,     0xe257b1af,
    0x1204bdaf,     0x001027f3,     0x00202cf3,     0x00302873,
    0xc0102d73,     0xc0002df3,     0xc0202273,     0x00080a13,
    0xfff34913,     0x40f00a33,     0x41b0043b,     0x0007009b,
    0x001cb593,     0x01a03833,     0x000ea6b3,     0x019025b3,
    0x003a15f3,     0x002f1bf3,     0x001b1373,     0x007f23b3,
    0x01fc3633,     0x6bb19673,     0x04722c73,     0x1fa43b73,
    0x5764d873,     0x59b76cf3,     0x7b34fb73,     0x3b9026f3,
    0x545f1073,     0x5e6d2073,     0x72643073,     0x11d45073,
    0x66d3e073,     0x5c647073,     0x8b893e03,     0xfcb3af83,
    0xe965e083,     0xbd2a1b83,     0xa9fb5c03,     0xf3268f83,
    0x9c3fca03,     0x3441bea3,     0x162b25a3,     0x10d510a3,
    0x1fe503a3,     0x80dfb787,     0x85b32a07,     0x068d37a7,
    0xf8eba827,     0x5804ad53,     0x5a0226d3,     0x00b53553,
    0x084f3353,     0x037abad3,     0x0b39be53,     0x103a33d3,
    0x191dba53,     0x1335b553,     0x1b8f3653,     0x99583c43,
    0x29b29647,     0x129d36c3,     0x422e1247,     0x0880cd4b,
    0x80a39a4f,     0x8ab34a4b,     0xabe8144f,     0xe00a9553,
    0x20f78b53,     0xe20f9b53,     0x224209d3,     0x2073a753,
    0x210819d3,     0x234a2f53,     0x22a51353,     0xe00101d3,
    0xe20b03d3,     0x21b10b53,     0x21f697d3,     0x23a90d53,
    0x221b9a53,     0x2072a853,     0x29ef80d3,     0x22a5a653,
    0x2b0185d3,     0x29151fd3,     0xa1b8a1d3,     0x2ad61ed3,
    0xa38e2153,     0xa12a9553,     0xa0ea83d3,     0xa33815d3,
    0xa25c06d3,     0xc00f34d3,     0xc0160b53,     0xd00a2fd3,
    0xd01c1cd3,     0xc02e8f53,     0xc0334c53,     0xd022be53,
    0xd0341cd3,     0x401f2dd3,     0x42078653,     0xc20f20d3,
    0xc2192e53,     0xd20d8fd3,     0xd2120bd3,     0xc22ca953,
    0xc234afd3,     0xd223a9d3,     0xd23523d3,
  };
// END  Generated code -- do not edit

  asm_check((unsigned int *)entry, insns, sizeof insns / sizeof insns[0]);
#endif
}

int AbstractAssembler::code_fill_byte() {
  return 0;
}

void Assembler::add(Register Rd, Register Rn, int64_t increment, Register temp) {
  if (is_imm_in_range(increment, 12, 0)) {
    addi(Rd, Rn, increment);
  } else {
    assert_different_registers(Rn, temp);
    li(temp, increment);
    add(Rd, Rn, temp);
  }
}

void Assembler::addw(Register Rd, Register Rn, int64_t increment, Register temp) {
  if (is_imm_in_range(increment, 12, 0)) {
    addiw(Rd, Rn, increment);
  } else {
    assert_different_registers(Rn, temp);
    li(temp, increment);
    addw(Rd, Rn, temp);
  }
}

void Assembler::sub(Register Rd, Register Rn, int64_t decrement, Register temp) {
  if (is_imm_in_range(-decrement, 12, 0)) {
    addi(Rd, Rn, -decrement);
  } else {
    assert_different_registers(Rn, temp);
    li(temp, decrement);
    sub(Rd, Rn, temp);
  }
}

void Assembler::subw(Register Rd, Register Rn, int64_t decrement, Register temp) {
  if (is_imm_in_range(-decrement, 12, 0)) {
    addiw(Rd, Rn, -decrement);
  } else {
    assert_different_registers(Rn, temp);
    li(temp, decrement);
    subw(Rd, Rn, temp);
  }
}

void Assembler::li(Register Rd, int64_t imm) {
  // int64_t is in range 0x8000 0000 0000 0000 ~ 0x7fff ffff ffff ffff
  int shift = 12;
  int64_t upper = imm, lower = imm;
  // Split imm to a lower 12-bit sign-extended part and the remainder, because addi will sign-extend the lower imm.
  lower = ((int32_t)imm << 20) >> 20;
  upper -= lower;

  // Test whether imm is a 32-bit integer.
  if (!(((imm) & ~(int64_t)0x7fffffff) == 0 ||
        (((imm) & ~(int64_t)0x7fffffff) == ~(int64_t)0x7fffffff))) {
    while (((upper >> shift) & 1) == 0) { shift++; }
    upper >>= shift;
    li(Rd, upper);
    slli(Rd, Rd, shift);
    if (lower != 0) {
      addi(Rd, Rd, lower);
    }
  }
  else {
    // 32-bit integer
    Register hi_Rd = zr;
    if (upper != 0) {
      lui(Rd, (int32_t)upper);
      hi_Rd = Rd;
    }
    if (lower != 0 || hi_Rd == zr) {
      addiw(Rd, hi_Rd, lower);
    }
  }
}

void Assembler::li64(Register Rd, int64_t imm) {
   // Load upper 32 bits. Upper = imm[63:32], but if imm[31] = 1 or (imm[31:28] == 0x7ff && imm[19] == 1),
   // upper = imm[63:32] + 1.
   int64_t lower = imm & 0xffffffff;
   lower -= ((lower << 44) >> 44);
   int64_t tmp_imm = ((uint64_t)(imm & 0xffffffff00000000)) + (uint64_t)lower;
   int32_t upper = (tmp_imm - (int32_t)lower) >> 32;

   // Load upper 32 bits
   int64_t up = upper, lo = upper;
   lo = (lo << 52) >> 52;
   up -= lo;
   up = (int32_t)up;
   lui(Rd, up);
   addi(Rd, Rd, lo);

   // Load the rest 32 bits.
   slli(Rd, Rd, 12);
   addi(Rd, Rd, (int32_t)lower >> 20);
   slli(Rd, Rd, 12);
   lower = ((int32_t)imm << 12) >> 20;
   addi(Rd, Rd, lower);
   slli(Rd, Rd, 8);
   lower = imm & 0xff;
   addi(Rd, Rd, lower);
}

void Assembler::li32(Register Rd, int32_t imm) {
  // int32_t is in range 0x8000 0000 ~ 0x7fff ffff, and imm[31] is the sign bit
  int64_t upper = imm, lower = imm;
  lower = (imm << 20) >> 20;
  upper -= lower;
  upper = (int32_t)upper;
  // lui Rd, imm[31:12] + imm[11]
  lui(Rd, upper);
  // use addiw to distinguish li32 to li64
  addiw(Rd, Rd, lower);
}

#define INSN(NAME, REGISTER)                                       \
  void Assembler::NAME(const address &dest, Register temp) {       \
    assert_cond(dest != NULL);                                     \
    int64_t distance = dest - pc();                                \
    if (is_imm_in_range(distance, 20, 1)) {                        \
      jal(REGISTER, distance);                                     \
    } else {                                                       \
      assert(temp != noreg, "temp must not be empty register!");   \
      int32_t offset = 0;                                          \
      movptr_with_offset(temp, dest, offset);                      \
      jalr(REGISTER, temp, offset);                                \
    }                                                              \
  }                                                                \
  void Assembler::NAME(Label &l, Register temp) {                  \
    jal(REGISTER, l, temp);                                        \
  }                                                                \

  INSN(j,   x0);
  INSN(jal, x1);

#undef INSN

#define INSN(NAME, REGISTER)                                       \
  void Assembler::NAME(Register Rs) {                              \
    jalr(REGISTER, Rs, 0);                                         \
  }

  INSN(jr,   x0);
  INSN(jalr, x1);

#undef INSN

void Assembler::ret() {
  jalr(x0, x1, 0);
}

#define INSN(NAME, REGISTER)                                      \
  void Assembler::NAME(const address &dest, Register temp) {      \
    assert_cond(dest != NULL);                                    \
    assert(temp != noreg, "temp must not be empty register!");    \
    int64_t distance = dest - pc();                               \
    if (is_offset_in_range(distance, 32)) {                       \
      auipc(temp, distance + 0x800);                              \
      jalr(REGISTER, temp, ((int32_t)distance << 20) >> 20);      \
    } else {                                                      \
      int32_t offset = 0;                                         \
      movptr_with_offset(temp, dest, offset);                     \
      jalr(REGISTER, temp, offset);                               \
    }                                                             \
  }

  INSN(call, x1);
  INSN(tail, x0);

#undef INSN

#define INSN(NAME, REGISTER)                                 \
  void Assembler::NAME(const Address &adr, Register temp) {  \
    switch(adr.getMode()) {                                  \
    case Address::literal: {                                 \
      code_section()->relocate(pc(), adr.rspec());           \
      NAME(adr.target(), temp);                              \
      break;                                                 \
    }                                                        \
    case Address::base_plus_offset:{                         \
      int32_t offset = 0;                                    \
      baseOffset(temp, adr, offset);                         \
      jalr(REGISTER, temp, offset);                          \
      break;                                                 \
    }                                                        \
    default:                                                 \
      ShouldNotReachHere();                                  \
    }                                                        \
  }

  INSN(j,    x0);
  INSN(jal,  x1);
  INSN(call, x1);
  INSN(tail, x0);

#undef INSN

void Assembler::wrap_label(Register r1, Register r2, Label &L, compare_and_branch_insn insn,
                           compare_and_branch_label_insn neg_insn, bool is_far) {
  if (is_far) {
    Label done;
    (this->*neg_insn)(r1, r2, done, /* is_far */ false);
    j(L);
    bind(done);
  } else {
    if (L.is_bound()) {
      (this->*insn)(r1, r2, target(L));
    } else {
      L.add_patch_at(code(), locator());
      (this->*insn)(r1, r2, pc());
    }
  }
}

void Assembler::wrap_label(Register Rt, Label &L, Register tmp, load_insn_by_temp insn) {
  if (L.is_bound()) {
    (this->*insn)(Rt, target(L), tmp);
  } else {
    L.add_patch_at(code(), locator());
    (this->*insn)(Rt, pc(), tmp);
  }
}

void Assembler::wrap_label(Register Rt, Label &L, jal_jalr_insn insn) {
  if (L.is_bound()) {
    (this->*insn)(Rt, target(L));
  } else {
    L.add_patch_at(code(), locator());
    (this->*insn)(Rt, pc());
  }
}

void Assembler::movptr_with_offset(Register Rd, address addr, int32_t &offset) {
  uintptr_t imm64 = (uintptr_t)addr;
#ifndef PRODUCT
  {
    char buffer[64];
    snprintf(buffer, sizeof(buffer), "0x%"PRIx64, imm64);
    block_comment(buffer);
  }
#endif
  assert(is_unsigned_imm_in_range(imm64, 47, 0) || (imm64 == (uintptr_t)-1), "48-bit overflow in address constant");
  // Load upper 32 bits
  int32_t imm = imm64 >> 16;
  int64_t upper = imm, lower = imm;
  lower = (lower << 52) >> 52;
  upper -= lower;
  upper = (int32_t)upper;
  lui(Rd, upper);
  addi(Rd, Rd, lower);

  // Load the rest 16 bits.
  slli(Rd, Rd, 11);
  addi(Rd, Rd, (imm64 >> 5) & 0x7ff);
  slli(Rd, Rd, 5);

  // Here, remove the addi instruct and return the offset directly. This offset will be used by following jalr/ld.
  offset = imm64 & 0x1f;
}

void Assembler::movptr(Register Rd, uintptr_t imm64) {
  movptr(Rd, (address)imm64);
}

void Assembler::movptr(Register Rd, address addr) {
  int offset = 0;
  movptr_with_offset(Rd, addr, offset);
  addi(Rd, Rd, offset);
}

void Assembler::ifence() {
  fence_i();
  if (UseConservativeFence) {
    fence(ir, ir);
  }
}

#define INSN(NAME, NEG_INSN)                                                         \
  void Assembler::NAME(Register Rs, Register Rt, const address &dest) {              \
    NEG_INSN(Rt, Rs, dest);                                                          \
  }                                                                                  \
  void Assembler::NAME(Register Rs, Register Rt, Label &l, bool is_far) {            \
    NEG_INSN(Rt, Rs, l, is_far);                                                     \
  }

  INSN(bgt,  blt);
  INSN(ble,  bge);
  INSN(bgtu, bltu);
  INSN(bleu, bgeu);
#undef INSN

#undef __

Address::Address(address target, relocInfo::relocType rtype) : _base(noreg), _offset(0), _mode(literal) {
  _target = target;
  switch (rtype) {
  case relocInfo::oop_type:
  case relocInfo::metadata_type:
    // Oops are a special case. Normally they would be their own section
    // but in cases like icBuffer they are literals in the code stream that
    // we don't have a section for. We use none so that we get a literal address
    // which is always patchable.
    break;
  case relocInfo::external_word_type:
    _rspec = external_word_Relocation::spec(target);
    break;
  case relocInfo::internal_word_type:
    _rspec = internal_word_Relocation::spec(target);
    break;
  case relocInfo::opt_virtual_call_type:
    _rspec = opt_virtual_call_Relocation::spec();
    break;
  case relocInfo::static_call_type:
    _rspec = static_call_Relocation::spec();
    break;
  case relocInfo::runtime_call_type:
    _rspec = runtime_call_Relocation::spec();
    break;
  case relocInfo::poll_type:
  case relocInfo::poll_return_type:
    _rspec = Relocation::spec_simple(rtype);
    break;
  case relocInfo::none:
    _rspec = RelocationHolder::none;
    break;
  default:
    ShouldNotReachHere();
    break;
  }
}

/*#define __ as->
void Address::lea(MacroAssembler *as, Register r) const {
  Relocation* reloc = _rspec.reloc();
  relocInfo::relocType rtype = (relocInfo::relocType) reloc->type();

  switch(_mode) {
  case base_plus_offset: {
    if (_offset == 0 && _base == r) // it's a nop
      break;
    if (_offset > 0)
      __ add(r, _base, _offset);
    else
      __ sub(r, _base, -_offset);
      break;
  }
  //case base_plus_offset_reg: {
    //__ add(r, _base, _index, _ext.op(), MAX(_ext.shift(), 0));
//    break;
 // }
  case literal: {
    if (rtype == relocInfo::none)
      __ mv(r, target());
    else
      __ movptr(r, (uint64_t)target());
    break;
  }
  default:
    ShouldNotReachHere();
  }
}*/
